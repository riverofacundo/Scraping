{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Pagina12 Final.ipynb","provenance":[],"authorship_tag":"ABX9TyOr4IUTNzouFJvF1hStX/6b"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"ZNRxjr9XrcVz","executionInfo":{"status":"ok","timestamp":1617421981155,"user_tz":180,"elapsed":927,"user":{"displayName":"Facundo Blas Rivero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPawB1vCVGHa09nyobmPX_zXQHM9KTQGIoz8Cb=s64","userId":"06832866268806121155"}}},"source":["def ScrapearP12():\n","  '''\n","  Scrapeo de informacion de todas las notas de todas las secciones\n","  de la pagina del diario \"Pagina12\".\n","\n","  Precondicion: tener instalados e importados los siguientes modulos: request, bs4, pandas, os\n","  y datetime. Ademas, se necesita que la pagina web de Pagina no cambie su codigo\n","  html luego de la fecha: 03/01/2021\n","  Poscondicion: Guarda en el directorio un archivo csv y devuelve un objeto de \n","  tipo DataFrame con la informacion scrapeada.\n","  '''\n","\n","  url = 'https://www.pagina12.com.ar/'\n","  try:\n","    p12 = requests.get(url)\n","  except Exception as e:\n","    print(\"error en la request\")\n","    print(e)\n","    print('\\n')\n","    return None\n","\n","  if p12.status_code != 200:\n","    print(f\"Error en request a p12: {url}\")\n","    print(f\"status coder = {p12.status_code}\")\n","    return None\n","\n","  try:\n","    p12 = BeautifulSoup(p12.text, 'html')\n","    secciones = p12.find('ul', class_='horizontal-list main-sections hide-on-dropdown').find_all('li')\n","    links_secciones = [seccion.find('a').get('href') for seccion in secciones]\n","  except Exception:\n","    print(\"Pagina12 ha cambiado su codigo html, se necesita actualizar el script.\")\n","    return None\n","\n","  notas = []\n","  for link in links_secciones:\n","    notas.extend(links_noticias(link))\n","\n","  data = []\n","  for i, nota in enumerate(notas):\n","    print(f\"Scrapeando nota {i}/{len(notas)}\")\n","    data.append(scrape_nota(nota))\n","  print(\"Scrapeo finalizado\")\n","  \n","  df = pd.DataFrame(data)\n","  folder = \"NotasP12_\" + datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n","  df.to_csv(folder+\".csv\")\n","\n","  return df"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"msknOKZWrtZ3","executionInfo":{"status":"ok","timestamp":1617421981155,"user_tz":180,"elapsed":921,"user":{"displayName":"Facundo Blas Rivero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPawB1vCVGHa09nyobmPX_zXQHM9KTQGIoz8Cb=s64","userId":"06832866268806121155"}}},"source":["def links_noticias(url_seccion):\n","  \n","  '''\n","  Dada una url de seccion regresa todos los links de dicha seccion\n","\n","  Precondicion: ingresar como unico parametros un objeto string con la url de\n","  la seccion de pagina12\n","  Poscondicion: devuelve una lista con todos los links de la seccion indicada.\n","  '''\n","\n","  try:\n","    sec = requests.get(url_seccion)\n","  except Exception as e:\n","    print(\"error en la request\")\n","    print(e)\n","    print('\\n')\n","    return None\n","  \n","  if sec.status_code != 200:\n","    print(f\"Error obteniendo notas de la seccion: {urlseccion}\")\n","    print(f\"status coder = {sec.status_code}\")\n","    return None\n","  \n","  s_seccion = BeautifulSoup(sec.text, 'html')\n","\n","  links = []\n","\n","  h2 = s_seccion.find_all('h2', class_='title-list')\n","  if h2:\n","     links.append(h2[0].a.get('href'))\n","  \n","  h3 = s_seccion.find_all('h3', class_='title-list')\n","  if h3:\n","    for h in h3:\n","      if h.a:\n","        links.append(h.a.get('href'))\n","  \n","  h4 = s_seccion.find_all('h4', class_='is-display-inline title-list')\n","  if h4:\n","    for h in h4:\n","      if h.a:\n","        links.append(h.a.get('href'))\n","\n","\n","  return links\n"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"C-GQ5ZUIrzin","executionInfo":{"status":"ok","timestamp":1617421981156,"user_tz":180,"elapsed":919,"user":{"displayName":"Facundo Blas Rivero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPawB1vCVGHa09nyobmPX_zXQHM9KTQGIoz8Cb=s64","userId":"06832866268806121155"}}},"source":["def scrape_nota(url_nota):\n","  '''\n","  Dada una url de una nota regresa la informacion scrapeada de la misma.\n","\n","  Precondicion: ingresar como unico parametros un objeto string con la url de\n","  la nota.\n","  Poscondicion: devuelve un diccionario con la informacion de la nota\n","  '''\n","  try:\n","    nota = requests.get(url_nota)\n","  except Exception as e:\n","    print(\"Error scrapeando URL\", url_nota)\n","    print(e)\n","    return None\n","\n","  if nota.status_code != 200:\n","    print(f\"Error obteniendo la nota {url_nota}\")\n","    print(f\"status coder = {nota.status_code}\")\n","    return None\n","  \n","  s_nota = BeautifulSoup(nota.text, 'html')\n","  nota_dict = obtener_info(s_nota)\n","  nota_dict['url'] = url_nota\n","\n","  return nota_dict"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"WkKhBC93r18w","executionInfo":{"status":"ok","timestamp":1617421981157,"user_tz":180,"elapsed":914,"user":{"displayName":"Facundo Blas Rivero","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgPawB1vCVGHa09nyobmPX_zXQHM9KTQGIoz8Cb=s64","userId":"06832866268806121155"}}},"source":["def obtener_info(s_nota):\n","  '''\n","  Dada un objeto \"soup\" de la libreria bs4 de una nota regresa la informacion \n","  scrapeada de la misma.\n","\n","  Precondicion: ingresar como unico parametros un objeto string con la url de\n","  la nota.\n","  Poscondicion: devuelve un diccionario con la informacion de la nota\n","  '''\n","  nota_dict={}\n","  #Fecha\n","  fecha = s_nota.find('span', attrs = {'pubdate':'pubdate'})\n","  if fecha:\n","    nota_dict[\"fecha\"] = fecha.get('datetime')\n","  else: nota_dict[\"fecha\"] = None\n","\n","  #Titulo\n","  titulo = s_nota.find('h1', class_='article-title')\n","  if titulo:\n","    nota_dict[\"titulo\"] = titulo.text\n","  else: nota_dict[\"titulo\"] = None\n","  \n","  #Volanta\n","  volanta = s_nota.find('h2', attrs = {'class':'article-prefix'})\n","  if volanta:\n","    nota_dict[\"volanta\"] = volanta.text\n","  else: nota_dict[\"volanta\"] = None\n","  \n","  #Copete\n","  copete = s_nota.find('div', attrs = {'class':'article-summary'})\n","  if copete:\n","    nota_dict[\"copete\"] = copete.text\n","  else: nota_dict[\"copete\"] = None\n","\n","  #Autor\n","  autor = s_nota.find('div', attrs = {'class':'article-author'})\n","  if autor:\n","    nota_dict[\"autor\"] = autor.text\n","  else: nota_dict[\"autor\"] = None\n","\n","  #Cuerpo\n","  cuerpo = s_nota.find('div', attrs = {'class':'article-text'}).find_all('p')\n","  if len(cuerpo)>10:\n","    nota_dict[\"cuerpo\"] = cuerpo\n","  else: nota_dict[\"cuerpo\"] = None\n","  \n","  '''  \n","  #Imagen\n","  media = s_nota.find('div', attrs = {'class':'article-main-media-image'})\n","  if media:\n","    media = media.find('div')\n","    if media:\n","      media = media.find_all('img')\n","  \n","  if media == None:\n","    nota_dict[\"imagen\"] = None\n","  else:\n","    imagen = media[-1].get('data-src')\n","    try:\n","      imagen = requests.get(imagen)\n","    except Exception as e:\n","      print(\"Error scrapeando URL\", imagen)\n","      print(e)\n","      return None\n","    if imagen.status_code != 200:\n","      print(f\"Error obteniendo la nota {imagen}\")\n","      print(f\"status coder = {imagen.status_code}\")\n","      return None\n","      \n","    nota_dict[\"imagen\"] = imagen.content\n","    \n","    '''\n","\n","  return nota_dict"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QXlD0J14uIWJ","outputId":"c4fee2aa-2560-4181-bd97-53650388fc42"},"source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import os\n","import datetime\n","\n","df = ScrapearP12()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Scrapeando nota 0/67\n","Scrapeando nota 1/67\n","Scrapeando nota 2/67\n","Scrapeando nota 3/67\n","Scrapeando nota 4/67\n","Scrapeando nota 5/67\n","Scrapeando nota 6/67\n","Scrapeando nota 7/67\n","Scrapeando nota 8/67\n","Scrapeando nota 9/67\n","Scrapeando nota 10/67\n","Scrapeando nota 11/67\n","Scrapeando nota 12/67\n","Scrapeando nota 13/67\n","Scrapeando nota 14/67\n","Scrapeando nota 15/67\n","Scrapeando nota 16/67\n","Scrapeando nota 17/67\n","Scrapeando nota 18/67\n","Scrapeando nota 19/67\n","Scrapeando nota 20/67\n","Scrapeando nota 21/67\n","Scrapeando nota 22/67\n","Scrapeando nota 23/67\n","Scrapeando nota 24/67\n","Scrapeando nota 25/67\n","Scrapeando nota 26/67\n","Scrapeando nota 27/67\n","Scrapeando nota 28/67\n","Scrapeando nota 29/67\n","Scrapeando nota 30/67\n","Scrapeando nota 31/67\n","Scrapeando nota 32/67\n","Scrapeando nota 33/67\n","Scrapeando nota 34/67\n","Scrapeando nota 35/67\n","Scrapeando nota 36/67\n","Scrapeando nota 37/67\n","Scrapeando nota 38/67\n","Scrapeando nota 39/67\n","Scrapeando nota 40/67\n","Scrapeando nota 41/67\n","Scrapeando nota 42/67\n","Scrapeando nota 43/67\n","Scrapeando nota 44/67\n","Scrapeando nota 45/67\n","Scrapeando nota 46/67\n","Scrapeando nota 47/67\n","Scrapeando nota 48/67\n","Scrapeando nota 49/67\n","Scrapeando nota 50/67\n","Scrapeando nota 51/67\n","Scrapeando nota 52/67\n","Scrapeando nota 53/67\n","Scrapeando nota 54/67\n","Scrapeando nota 55/67\n","Scrapeando nota 56/67\n","Scrapeando nota 57/67\n","Scrapeando nota 58/67\n","Scrapeando nota 59/67\n","Scrapeando nota 60/67\n","Scrapeando nota 61/67\n","Scrapeando nota 62/67\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rE8Yvkj4wWoR"},"source":["df.head(5)"],"execution_count":null,"outputs":[]}]}